{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Credit Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab material is largely self-contained. We assume that every student has already taken STAT7008 or knows some basic operations of Python. Noet that you may use Anaconda to run the .ipynb file. For the installation of Anaconda, please see https://conda.io/docs/user-guide/install/index.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lab 6, you will learn how to:\n",
    "\n",
    "a. build a credit scorecard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful libraries for this Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. numpy, for data array. \n",
    "\n",
    "b. sklearn, for modelling.\n",
    "\n",
    "c. os, for the working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/renjielu/PycharmProjects/DM8017/DM_Lab6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import os\n",
    "\n",
    "wd = os.getcwd() # Set your working directory. \n",
    "print wd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the data called accepts, which can be downloaded from Moodle. In this data set, variable called bad is the target variable. For simplicity, we only consider two input variables: bureau_score and age_oldest_tr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bankruptcy', u'bad', u'app_id', u'tot_derog', u'tot_tr', u'age_oldest_tr', u'tot_open_tr', u'tot_rev_tr', u'tot_rev_debt', u'tot_rev_line', u'rev_util', u'bureau_score', u'purch_price', u'msrp', u'down_pyt', u'purpose', u'loan_term', u'loan_amt', u'ltv', u'tot_income', u'used_ind', u'weight']\n",
      "   bankruptcy  bad  app_id  tot_derog  tot_tr  age_oldest_tr  tot_open_tr  \\\n",
      "0         0.0  0.0  1001.0        6.0     7.0           46.0          NaN   \n",
      "1         0.0  0.0  1002.0        0.0    21.0          153.0          6.0   \n",
      "2         0.0  0.0  1003.0        0.0    29.0          194.0          4.0   \n",
      "3         0.0  1.0  1005.0        2.0    20.0          129.0          8.0   \n",
      "4         1.0  0.0  1006.0        2.0    10.0          108.0          6.0   \n",
      "\n",
      "   tot_rev_tr  tot_rev_debt  tot_rev_line   ...    purch_price     msrp  \\\n",
      "0         NaN           NaN           NaN   ...       19678.00  17160.0   \n",
      "1         1.0          97.0        4637.0   ...       28615.00  27950.0   \n",
      "2         2.0        4798.0       22791.0   ...       25750.71  24477.0   \n",
      "3         6.0        5807.0       15763.0   ...       15314.00  18450.0   \n",
      "4         4.0        3352.0        4079.0   ...       21197.61  22238.0   \n",
      "\n",
      "   down_pyt  purpose  loan_term  loan_amt    ltv  tot_income  used_ind  weight  \n",
      "0    947.15    LEASE       36.0  18730.85  109.0     4800.00       0.0    4.75  \n",
      "1   1500.00    LEASE       60.0  27112.96   97.0     5833.33       0.0    4.75  \n",
      "2     10.70    LEASE       48.0  25740.01  105.0     2308.33       0.0    4.75  \n",
      "3   1015.18    LEASE       63.0  14298.82   78.0     4083.33       1.0    1.00  \n",
      "4      0.00    LEASE       60.0  22167.51  100.0     5783.33       0.0    4.75  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "accept = pd.read_sas(wd+'/accepts.sas7bdat')\n",
    "\n",
    "print list(accept) # for column names.\n",
    "print accept.head()\n",
    "\n",
    "Y = accept['bad']\n",
    "X = accept[['age_oldest_tr', 'bureau_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the two input varibales into 5 parts. We compute the weight of evidence (WOE) and information value (IV) for each variables. The results can be seen as follows. Usually, low IV, say $<$ 0.15, means weak  classification power, while high IV, like $>$ 0.4, means strong power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOE of X1:  [-0.38801869  0.18179713  0.82635172  1.02855501 -0.66625426  0.80901651]\n",
      "WOE of X2:  [ 0.719889   -0.47763081  2.18955664 -0.6651725  -1.59233598 -1.27823822]\n",
      "IV of X1:  0.203552802313\n",
      "IV of X2:  0.672197204136\n"
     ]
    }
   ],
   "source": [
    "cut_x1 = pd.cut(X.iloc[:,0],bins=5)\n",
    "cut_x2 = pd.cut(X.iloc[:,1],bins=5)\n",
    "\n",
    "cut_x1_u = pd.unique(list(cut_x1))\n",
    "cut_x2_u = pd.unique(list(cut_x2))\n",
    "\n",
    "# group the target variable by the binned variable. \n",
    "\n",
    "def group_y(cut_x, cut_x_u, Y):\n",
    "    group_y_by_x = []\n",
    "    for i in range(len(cut_x_u)): \n",
    "        tmp = [y for x,y in zip(cut_x,Y) if x is cut_x_u[i]]\n",
    "        group_y_by_x.append(tmp) \n",
    "    return group_y_by_x\n",
    "\n",
    "group_y_by_x1 = group_y(cut_x1, cut_x1_u, Y)\n",
    "group_y_by_x2 = group_y(cut_x2, cut_x2_u, Y)\n",
    "\n",
    "\n",
    "# compuate WOE and IV\n",
    "\n",
    "def WOE_and_IV_y(group_y_by_x):\n",
    "    \n",
    "    Ni = []\n",
    "    Ni_bad = []  \n",
    "    for i in range(len(group_y_by_x)):\n",
    "        Ni_bad.append(sum(group_y_by_x[i]))\n",
    "        Ni.append(len(group_y_by_x[i]))\n",
    "    \n",
    "    Ni_good = np.array(Ni) - np.array(Ni_bad)\n",
    "    \n",
    "    N_bad = sum(Ni_bad)\n",
    "    N_good = sum(Ni_good)\n",
    "    \n",
    "    pi_good = (np.array(Ni_good)+0.5)/N_good # to avoid pure case.\n",
    "    pi_bad = (np.array(Ni_bad)+0.5)/N_bad\n",
    "    \n",
    "    WOE = np.log((pi_good)/(pi_bad))\n",
    "    \n",
    "    IV = np.sum((pi_good-pi_bad)*WOE)\n",
    "    return WOE, IV\n",
    "\n",
    "WOE_x1, IV_x1 = WOE_and_IV_y(group_y_by_x1)\n",
    "WOE_x2, IV_x2 = WOE_and_IV_y(group_y_by_x2)\n",
    "\n",
    "print 'WOE of X1: ',WOE_x1\n",
    "print 'WOE of X2: ',WOE_x2\n",
    "print 'IV of X1: ',IV_x1\n",
    "print 'IV of X2: ',IV_x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the WOEs, we can build a logistic model. After we obtain the estimated odds, we simply follow the same setting in the lecture note to give a score for each applicant, namely, we scale the scorecard such that odds of 50:1 at 600 points and the odds to double every 20 points. So, the offset and factor are 487.123 and 28.8539, respectively. We print the first five scores. Follow the formula in the points allcoation of lecture note, a corresponding scorecard is provided. Note that nan means missing value.\n",
    "\n",
    "In this lab material, we do not do reject inference. You may try it by yourself. Note that based on the code in this material, it is easy to create a class to rebuild a scorecard after the reject inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 662.25049309  732.03035118  567.70967377  567.70967377  544.74863715]\n",
      "for age_oldest_tr\n",
      "interval is  (0.413, 118.4] score is  244.014846994\n",
      "interval is  (118.4, 235.8] score is  244.350212734\n",
      "interval is  (235.8, 353.2] score is  244.729566056\n",
      "interval is  (353.2, 470.6] score is  244.848573027\n",
      "interval is  nan score is  243.851091141\n",
      "interval is  (470.6, 588.0] score is  244.719363397\n",
      "\n",
      "\n",
      "for bureau_score\n",
      "interval is  (686.0, 767.0] score is  244.911422081\n",
      "interval is  (605.0, 686.0] score is  243.799875399\n",
      "interval is  (767.0, 848.0] score is  246.275578381\n",
      "interval is  nan score is  243.625797825\n",
      "interval is  (442.595, 524.0] score is  242.765197877\n",
      "interval is  (524.0, 605.0] score is  243.056745726\n"
     ]
    }
   ],
   "source": [
    "# creat the input matrix.\n",
    "\n",
    "WOE_input1 = np.array([WOE_x1[list(cut_x1_u).index(x)] for x in cut_x1])\n",
    "WOE_input2 = np.array([WOE_x2[list(cut_x2_u).index(x)] for x in cut_x2])\n",
    "\n",
    "WOE_input = np.hstack((WOE_input1.reshape(-1 ,1), WOE_input2.reshape((-1, 1))))\n",
    "\n",
    "logr = linear_model.LogisticRegression(C=1000.0) \n",
    "logr.fit(WOE_input, Y.values)\n",
    "logr_predict_proba = logr.predict_proba(WOE_input)\n",
    "\n",
    "# odds = np.exp(logr_predict_proba[:,0]/logr_predict_proba[:,1])\n",
    "\n",
    "offset = 487.123\n",
    "factor = 28.8539\n",
    "\n",
    "scores = 487.123 + 28.8539 * (logr_predict_proba[:,0]/logr_predict_proba[:,1])\n",
    "\n",
    "print scores[:5]\n",
    "\n",
    "a = logr.intercept_\n",
    "beta_age = logr.coef_[0][0]\n",
    "beta_bur = logr.coef_[0][1]\n",
    "\n",
    "n = 2. # we use two variables here\n",
    "\n",
    "scorecard_x1 = np.hstack((cut_x1_u.reshape(-1,1), (-(WOE_x1*beta_age+a/n)+offset/n).reshape(-1,1)))\n",
    "scorecard_x2 = np.hstack((cut_x2_u.reshape(-1,1), (-(WOE_x2*beta_bur+a/n)+offset/n).reshape(-1,1)))\n",
    "\n",
    "print 'for age_oldest_tr' \n",
    "for i in range(scorecard_x1.shape[0]):\n",
    "    print 'interval is ', scorecard_x1[i,0], 'score is ', scorecard_x1[i,1]\n",
    "\n",
    "print '\\n'    \n",
    "    \n",
    "print 'for bureau_score'\n",
    "\n",
    "for i in range(scorecard_x2.shape[0]):\n",
    "    print 'interval is ', scorecard_x2[i,0], 'score is ', scorecard_x2[i,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
